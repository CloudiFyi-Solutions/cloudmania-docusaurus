"use strict";(self.webpackChunkcloudmania=self.webpackChunkcloudmania||[]).push([[3294],{840:e=>{e.exports=JSON.parse('{"permalink":"/blog/migrate-private-pypi-packages","editUrl":"https://github.com/CloudiFyi-Solutions/tree/main/packages/create-docusaurus/templates/shared/blog/2025-05-02/index.md","source":"@site/blog/2025-05-02/index.md","title":"Migrating Private PyPI Packages Across Azure DevOps Organizations","description":"Introduction","date":"2025-05-02T00:00:00.000Z","tags":[{"inline":false,"label":"Python","permalink":"/blog/tags/python","description":"Python programming language"},{"inline":false,"label":"Azure DevOps","permalink":"/blog/tags/azure-devops","description":"Azure DevOps pipelines, repos, and artifacts"},{"inline":false,"label":"PyPI","permalink":"/blog/tags/pypi","description":"Python Package Index and private package feeds"},{"inline":false,"label":"Package Management","permalink":"/blog/tags/package-management","description":"Managing and distributing software packages"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops","description":"devops"}],"readingTime":4.17,"hasTruncateMarker":true,"authors":[{"name":"Umar Khan","title":"DevSecOps / Cloud / Platform Engineer","url":"https://github.com/ukhan262","page":{"permalink":"/blog/authors/ukhan"},"socials":{"x":"https://x.com/ukhan262","github":"https://github.com/ukhan262"},"imageURL":"https://github.com/ukhan262.png","key":"ukhan"}],"frontMatter":{"slug":"migrate-private-pypi-packages","title":"Migrating Private PyPI Packages Across Azure DevOps Organizations","authors":["ukhan"],"tags":["python","azure-devops","pypi","package-management","devops"]},"unlisted":false,"nextItem":{"title":"Reusable Terraform Deployment Workflow","permalink":"/blog/reusable-terraform-deployment"}}')},7319:(e,n,a)=>{a.d(n,{A:()=>t});const t=a.p+"assets/images/image-defe06bbc482aca6da4a8cd6fc964a16.png"},8453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>o});var t=a(6540);const r={},i=t.createContext(r);function s(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(i.Provider,{value:n},e.children)}},8659:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>d});var t=a(840),r=a(4848),i=a(8453);const s={slug:"migrate-private-pypi-packages",title:"Migrating Private PyPI Packages Across Azure DevOps Organizations",authors:["ukhan"],tags:["python","azure-devops","pypi","package-management","devops"]},o=void 0,l={authorsImageUrls:[void 0]},d=[{value:"Introduction",id:"introduction",level:2},{value:"The Problem",id:"the-problem",level:2},{value:"The Goal",id:"the-goal",level:2},{value:"The Solution",id:"the-solution",level:2},{value:"Source Code",id:"source-code",level:2},{value:"How it Works?",id:"how-it-works",level:2},{value:"Expected Output",id:"expected-output",level:2}];function p(e){const n={code:"code",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:a(7319).A+"",width:"720",height:"480"})}),"\n",(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"Migrating private PyPI packages between Azure DevOps organizations may sound like a trivial task\u2014until you realize you don\u2019t have access to the source organization or the upstream feed."}),"\n",(0,r.jsx)(n.p,{children:"In this article, I walk through how I moved packages from a private PyPI feed in one Azure DevOps organization to another, without needing any backend or admin access to the source organization."}),"\n",(0,r.jsx)(n.h2,{id:"the-problem",children:"The Problem"}),"\n",(0,r.jsx)(n.p,{children:"Our organization had multiple Azure DevOps orgs, each managing its own feeds for private Python packages. As part of an enterprise-wide initiative to centralize DevOps operations, we had to merge these orgs and move all internal packages into a unified feed."}),"\n",(0,r.jsx)(n.p,{children:"Unfortunately, this wasn\u2019t just a matter of updating setup.py and republishing. In many cases:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The source repositories no longer existed."}),"\n",(0,r.jsx)(n.li,{children:"The build pipelines had been decommissioned."}),"\n",(0,r.jsx)(n.li,{children:"The only remaining evidence of the package was its artifact in the original feed."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"the-goal",children:"The Goal"}),"\n",(0,r.jsx)(n.p,{children:"Build a CLI tool that:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Migrates PyPI packages across Azure DevOps orgs or projects"}),"\n",(0,r.jsx)(n.li,{children:"Works even if the original source code is gone"}),"\n",(0,r.jsx)(n.li,{children:"Handles .whl and .tar.gz packages"}),"\n",(0,r.jsx)(n.li,{children:"Skips already uploaded or deleted versions\n-Is resilient, idempotent, and easy to use"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"the-solution",children:"The Solution"}),"\n",(0,r.jsx)(n.p,{children:"I built a CLI in Python that:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Lists available package versions from the source feed (using HTML scraping and Azure DevOps REST APIs)"}),"\n",(0,r.jsx)(n.li,{children:"Downloads each package file using HTTP Basic Auth (via Personal Access Token)"}),"\n",(0,r.jsx)(n.li,{children:"Uploads to the destination feed using twine, while handling common errors like duplicates or deleted versions"}),"\n",(0,r.jsx)(n.li,{children:"It supports both organization-scoped and project-scoped feeds, and it can be run repeatedly without breaking anything."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"source-code",children:"Source Code"}),"\n",(0,r.jsx)(n.p,{children:"Save the source code as migrate_pypi_cli.py"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import argparse\nimport os\nimport re\nimport requests\nimport subprocess\nfrom pathlib import Path\nfrom bs4 import BeautifulSoup\n\nUSER = "user"\nDOWNLOAD_DIR = Path("downloaded_packages")\n\n\ndef build_urls(org, feed, project, package):\n    base_path = f"{org}/{project}" if project else org\n    simple_url = f"https://pkgs.dev.azure.com/{base_path}/_packaging/{feed}/pypi/simple/"\n    upload_url = f"https://pkgs.dev.azure.com/{base_path}/_packaging/{feed}/pypi/upload"\n    api_url = f"https://feeds.dev.azure.com/{base_path}/_apis/packaging/feeds/{feed}/pypi/packages/{package}/versions?api-version=7.1-preview.1"\n    return simple_url, upload_url, api_url\n\n\ndef get_versions(package, index_url, auth):\n    print(f"\ud83d\udd0d Fetching versions for {package} from {index_url}...")\n    r = requests.get(f"{index_url}{package}/", auth=auth)\n    if r.status_code != 200:\n        raise Exception(f"\u274c Failed to fetch index: {r.status_code} - {r.text}")\n\n    soup = BeautifulSoup(r.text, "html.parser")\n    files = {}\n    for tag in soup.find_all("a"):\n        href = tag.get("href", "").split("#")[0]\n        filename = href.split("/")[-1]\n        match = re.search(rf"{package.replace(\'-\', \'_\')}-([0-9a-zA-Z.\\-_]+)\\.(whl|tar\\.gz)", filename)\n        if match:\n            version = match.group(1)\n            files[version] = href\n    print(f"\u2705 Found {len(files)} versions: {sorted(files.keys())}")\n    return files\n\n\ndef download_file(url, dest_path, auth):\n    r = requests.get(url, auth=auth)\n    if r.status_code == 200:\n        with open(dest_path, "wb") as f:\n            f.write(r.content)\n        print(f"\u2705 Downloaded: {dest_path.name}")\n    else:\n        raise Exception(f"\u274c Failed to download {url} - {r.status_code}\\n{r.text}")\n\n\ndef destination_version_exists(version, api_url, auth, uploaded_versions):\n    if version in uploaded_versions:\n        return True\n    r = requests.get(api_url, auth=auth)\n    if r.status_code == 200:\n        existing = {v["version"] for v in r.json().get("value", [])}\n        uploaded_versions.update(existing)\n        return version in existing\n    return False\n\n\ndef upload_with_twine(filepath, version, upload_url, auth_password, api_url, uploaded_versions):\n    if destination_version_exists(version, api_url, auth_password, uploaded_versions):\n        print(f"\u26a0\ufe0f Skipping {version}: already exists.")\n        return\n\n    print(f"\u2b06\ufe0f Uploading {filepath.name}...")\n    cmd = [\n        "twine", "upload",\n        "--repository-url", upload_url,\n        "-u", USER,\n        "-p", auth_password,\n        str(filepath)\n    ]\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    stderr_lower = result.stderr.lower()\n    if result.returncode == 0 or "already contains file" in result.stdout.lower():\n        print(f"\u2705 Uploaded or already exists: {filepath.name}")\n        uploaded_versions.add(version)\n    elif "has been deleted" in stderr_lower and "cannot be restored" in stderr_lower:\n        print(f"\u26a0\ufe0f Skipped {filepath.name}: deleted and cannot be re-pushed.")\n    else:\n        print(f"\u274c Failed to upload {filepath.name}\\n{result.stdout}\\n{result.stderr}")\n\n\ndef main():\n    parser = argparse.ArgumentParser(description="Migrate PyPI packages between Azure DevOps feeds.")\n    parser.add_argument("--source-org", required=True)\n    parser.add_argument("--source-feed", required=True)\n    parser.add_argument("--source-pat", required=True)\n    parser.add_argument("--package", required=True)\n    parser.add_argument("--dest-org", required=True)\n    parser.add_argument("--dest-feed", required=True)\n    parser.add_argument("--dest-pat", required=True)\n    parser.add_argument("--source-project", default="")\n    parser.add_argument("--dest-project", default="")\n    args = parser.parse_args()\n\n    source_index, _, _ = build_urls(args.source_org, args.source_feed, args.source_project, args.package)\n    _, dest_upload, dest_api = build_urls(args.dest_org, args.dest_feed, args.dest_project, args.package)\n\n    package_dir = DOWNLOAD_DIR / args.package\n    package_dir.mkdir(parents=True, exist_ok=True)\n\n    uploaded_versions = set()\n    file_map = get_versions(args.package, source_index, auth=(USER, args.source_pat))\n\n    for version, url in file_map.items():\n        filename = url.split("/")[-1]\n        dest_file = package_dir / filename\n        if not dest_file.exists():\n            try:\n                download_file(url, dest_file, auth=(USER, args.source_pat))\n            except Exception as e:\n                print(f"\u26d4 Skipping {version}: {e}")\n                continue\n\n    for wheel in package_dir.glob("*"):\n        match = re.search(rf"{args.package.replace(\'-\', \'_\')}-([0-9a-zA-Z.\\-_]+)\\.(whl|tar\\.gz)", wheel.name)\n        if not match:\n            print(f"\u26a0\ufe0f Skipping unrecognized file: {wheel.name}")\n            continue\n        version = match.group(1)\n        try:\n            upload_with_twine(wheel, version, dest_upload, args.dest_pat, dest_api, uploaded_versions)\n        except Exception as e:\n            print(f"\u26d4 Upload error for {wheel.name}: {e}")\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,r.jsx)(n.h2,{id:"how-it-works",children:"How it Works?"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Project Scoped\npython migrate_pypi_cli.py \\\n  --source-org "SourceOrg" \\\n  --source-feed ProjectScopedFeed \\\n  --source-pat $AZURE_PAT \\\n  --package python-utilities-tfc \\\n  --dest-org "DestinationOrg" \\\n  --dest-feed ProjectScopedFeed \\\n  --dest-pat $DEST_PAT \\\n  --source-project Automation \\\n  --dest-project Automation\n\n# Org Scoped\npython migrate_pypi_cli.py \\\n  --source-org "SourceOrg" \\\n  --source-feed "SourceOrg" \\\n  --source-pat $AZURE_PAT \\\n  --package python-utilities-tfc \\\n  --dest-org "DestinationOrg" \\\n  --dest-feed "DestinationOrg \\\n  --dest-pat $DEST_PAT \\\n'})}),"\n",(0,r.jsx)(n.p,{children:"The tool:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Authenticates to both feeds using your PAT"}),"\n",(0,r.jsx)(n.li,{children:"Downloads any .whl or .tar.gz that isn\u2019t already present"}),"\n",(0,r.jsx)(n.li,{children:"Uploads each to the destination feed using twine"}),"\n",(0,r.jsx)(n.li,{children:"Skips anything that already exists or was deleted"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"expected-output",children:"Expected Output"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\ud83d\udd0d Fetching versions for python-utilities-tfc from https://pkgs.dev.azure.com/...\n\u2705 Found 2 versions: ['0.5.1', '1.9.0']\n\n\u2b07\ufe0f Downloading: python_utilities_tfc-0.5.1-py3-none-any.whl\n\u2705 Downloaded: python_utilities_tfc-0.5.1-py3-none-any.whl\n\n\u2b06\ufe0f Uploading: python_utilities_tfc-0.5.1-py3-none-any.whl\n\u26a0\ufe0f Skipping upload: version 0.5.1 already exists in destination.\n\n\u2b06\ufe0f Uploading: python_utilities_tfc-1.9.0-py3-none-any.whl\n\u2705 Successfully uploaded: python_utilities_tfc-1.9.0-py3-none-any.whl\n"})})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}}}]);